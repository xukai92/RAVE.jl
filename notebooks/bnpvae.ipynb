{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLToolkit, Logging, ProgressMeter, Statistics, PyCall, ArgParse, Printf, Dates, LaTeXStrings\n",
    "import Random\n",
    "const tbX = pyimport(\"tensorboardX\")\n",
    "\n",
    "MLToolkit.Knet.gpu(false)\n",
    "const Normal = BatchNormal{FT}\n",
    "\n",
    "# Auto-reload packages imported afterwards if in Jupyter\n",
    "@jupyter using Revise\n",
    "\n",
    "using RRVAE\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = ArgParseSettings()\n",
    "\n",
    "@add_arg_table settings begin\n",
    "    \"--alpha\"\n",
    "        arg_type = Real\n",
    "        default = -1\n",
    "    \"--k_max\"\n",
    "        arg_type = Int\n",
    "        default = -1\n",
    "    \"--dataset\"\n",
    "        arg_type = String\n",
    "        required = true\n",
    "        range_tester = (d->d==\"synth\"||d==\"synth_large\"||d==\"mnist\"||d==\"fmnist\")\n",
    "    \"--tr_sz\"\n",
    "        arg_type = Int\n",
    "        default = -1\n",
    "    \"--te_sz\"\n",
    "        arg_type = Int\n",
    "        default = -1\n",
    "    \"--h_dim\"\n",
    "        arg_type = Int\n",
    "        default = -1\n",
    "    \"--batch_size\"\n",
    "        arg_type = Int\n",
    "        required = true\n",
    "    \"--n_epochs\"\n",
    "        arg_type = Int\n",
    "        default = -1\n",
    "    \"--bnp\"\n",
    "        arg_type = String\n",
    "        required = true\n",
    "        range_tester = (b->b==\"ibp\"||b==\"crp\")\n",
    "    \"--inf\"\n",
    "        arg_type = String\n",
    "        required = true\n",
    "        range_tester = (i->i==\"mf\"||i==\"s\"||i==\"rrs\")\n",
    "    \"--obs\"\n",
    "        arg_type = String\n",
    "        required = true\n",
    "        range_tester = (o->o==\"gauss\"||o==\"ber\")\n",
    "    \"--is_deep\"\n",
    "        arg_type = Bool\n",
    "        required = true\n",
    "    \"--lr\"\n",
    "        arg_type = Float64\n",
    "        default = 0.001\n",
    "    \"--beta1\"\n",
    "        arg_type = Float64\n",
    "        default = 0.99\n",
    "    \"--beta2\"\n",
    "        arg_type = Float64\n",
    "        default = 0.999\n",
    "    \"--gpu_id\"\n",
    "        arg_type = Int\n",
    "        default = -1\n",
    "    \"--eval_every\"\n",
    "        arg_type = Int\n",
    "        default = -1\n",
    "    \"--check_every\"\n",
    "        arg_type = Int\n",
    "        default = -1\n",
    "    \"--continue\"\n",
    "        action = :store_true\n",
    "    \"--store\"\n",
    "        action = :store_true\n",
    "end\n",
    "\n",
    "args_str_with_line_breaks = \"\"\"\n",
    "--dataset synth --batch_size 200 --bnp ibp --inf rrs --obs gauss --is_deep true --gpu_id 3\n",
    "--store\"\"\"\n",
    "\n",
    "args_str = replace(args_str_with_line_breaks, \"\\n\" => \" \")\n",
    "\n",
    "args = parse_args(isjupyter() ? args_str : ARGS, settings; as_symbols=true)\n",
    "\n",
    "# Update args from pre-set if not specified\n",
    "PRESETARGS = Dict(\n",
    "    \"synth\"       => Dict(:alpha=>04.0, :k_max=>09, :h_dim=>050, :tr_sz=>02_400, :te_sz=>00_400, \n",
    "                          :n_epochs=>(args[:inf] == \"rrs\" ? 3_000 : 1_500), :eval_every=>25, :check_every=>50),\n",
    "    \"synth_large\" => Dict(:alpha=>08.0, :k_max=>25, :h_dim=>150, :tr_sz=>12_000, :te_sz=>02_000, \n",
    "                          :n_epochs=>(args[:inf] == \"rrs\" ? 0_600 : 0_300), :eval_every=>05, :check_every=>010),\n",
    "    \"mnist\"       => Dict(:alpha=>10.0, :k_max=>50, :h_dim=>500, :tr_sz=>60_000, :te_sz=>10_000, \n",
    "                          :n_epochs=>(args[:inf] == \"rrs\" ? 0_150 : 0_060), :eval_every=>01, :check_every=>002),\n",
    "    \"fmnist\"      => Dict(:alpha=>20.0, :k_max=>50, :h_dim=>500, :tr_sz=>60_000, :te_sz=>10_000, \n",
    "                          :n_epochs=>(args[:inf] == \"rrs\" ? 0_150 : 0_060), :eval_every=>01, :check_every=>002)\n",
    ")\n",
    "for preset_arg in keys(PRESETARGS[\"synth\"])\n",
    "    if !(preset_arg in keys(args)) || args[preset_arg] == -1\n",
    "        args[preset_arg] = PRESETARGS[args[:dataset]][preset_arg]\n",
    "    end\n",
    "end\n",
    "\n",
    "@jupyter println(args_str)\n",
    "\n",
    "println(\"Parsed args:\")\n",
    "for (arg, val) in args\n",
    "    println(\"$(\"$(@sprintf(\"%17s\", arg))\")  =>  $val\")\n",
    "end\n",
    "\n",
    "# NOTE: Ckpt FMT = (jupyter,filename)/bnp-inf-arch-obs/args_str_flat\n",
    "\n",
    "args_str_flat, args_str_flat_method, args_str_flat_tr = flatstr(args)\n",
    "file_name = replace(basename(@__FILE__), \".jl\" => \"\")\n",
    "@jupyter file_name = \"jupyter\"\n",
    "# @jupyter file_name = \"bnpvae\"\n",
    "\n",
    "exp_name = \"$file_name/$args_str_flat_method/$args_str_flat\"\n",
    "\n",
    "log_dir = \"../log/$exp_name\"\n",
    "if !ispath(log_dir) \n",
    "    mkpath(log_dir) \n",
    "end\n",
    "\n",
    "# Create logger and set it to global\n",
    "logger_io = open(\"$log_dir/log.txt\", \"w+\")\n",
    "logger = CombinedLogger(SimpleLogger(stderr), SimpleLogger(logger_io))\n",
    "global_logger(logger)\n",
    "\n",
    "# Log parsed args\n",
    "@info \"Parsed args\" args...\n",
    "\n",
    "model_path = \"$log_dir/model.jld2\"\n",
    "\n",
    "# -1 means not specified. Knet will use any GPU which is free then.\n",
    "args[:gpu_id] != -1 && Knet.gpu(args[:gpu_id])\n",
    "@info \"On GPU\" Knet.gpu()\n",
    "\n",
    "@info \"Exp info\" exp_name log_dir\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data; use `@doc get_data` to see how `is_save=true` behaves\n",
    "x_tr, x_te, features = get_data(args; is_save=true)\n",
    "@info \"Loaded data\" size(x_tr)\n",
    "x_dim = size(x_tr, 1)\n",
    "\n",
    "# Shuffle dataset\n",
    "Random.seed!(1234)\n",
    "\n",
    "x_tr = x_tr[:,Random.randperm(args[:tr_sz])]\n",
    "x_te = x_te[:,Random.randperm(args[:te_sz])]\n",
    "\n",
    "@jupyter begin \n",
    "    plt.figure(figsize=(16, 9))\n",
    "    ax = plot_grayimg(x_tr, 3, 20)\n",
    "    ax.\"set_title\"(\"Data samples\")\n",
    "\n",
    "    if features != nothing\n",
    "        plt.figure(figsize=(16, 9))\n",
    "        ax = plot_grayimg(features)\n",
    "        ax.\"set_title\"(\"Features\")\n",
    "    end\n",
    "end\n",
    "\n",
    "batch_size = args[:batch_size]\n",
    "tr_loader = BatchDataLoader(batch_size, x_tr; atype=AT)\n",
    "te_loader = BatchDataLoader(batch_size, x_te; atype=AT)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[:continue] && ispath(model_path)\n",
    "    model_dict = Knet.load(\"$model_path\")\n",
    "    vae = model_dict[\"vae\"]\n",
    "    epoch_end = model_dict[\"epoch\"]\n",
    "    @info \"Loaded `$model_path`\"\n",
    "else\n",
    "    if ispath(model_path)\n",
    "        @warn \"$model_path existis!!\"\n",
    "    end\n",
    "    vae = if args[:bnp] == \"ibp\"\n",
    "        IBPVAE(x_dim, args)\n",
    "    elseif args[:bnp] == \"crp\"\n",
    "        CRPVAE(x_dim, args)\n",
    "    else\n",
    "        throw(\"[IBPVAE] Unkown BNP model: $bnp\")\n",
    "    end\n",
    "    if args[:inf] == \"rrs\"\n",
    "        initoptim!(vae, (; kwargs...) -> DynamicAdam(true; kwargs...); lr=args[:lr], beta1=args[:beta1], beta2=args[:beta2])\n",
    "        vae.rho.opt = SGD(; lr=1.5args[:lr])\n",
    "    else\n",
    "        initoptim!(vae, Adam; lr=args[:lr], beta1=args[:beta1], beta2=args[:beta2])\n",
    "    end\n",
    "    epoch_end = 0\n",
    "end\n",
    "\n",
    "@info vae\n",
    "\n",
    "# Note: log FMT = (jupyter,filename)/inference/args_str_flat/current_time\n",
    "writer_dir = log_dir\n",
    "@jupyter writer_dir *= \"/$(Dates.format(now(), \"dd-u-yyyy-H-M-S\"))\"\n",
    "                \n",
    "writer = tbX.SummaryWriter(writer_dir)\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_start = epoch_end + 1\n",
    "epoch_end = epoch_start + args[:n_epochs] - 1\n",
    "\n",
    "t_tr, t_te = 0, 0\n",
    "\n",
    "t_total = @elapsed let pm=Progress(args[:n_epochs], desc=\"Training\", barlen=31)\n",
    "    for epoch = epoch_start:epoch_end\n",
    "        global t_tr, t_te\n",
    "        t_tr += @elapsed avg_loss = train!(vae, tr_loader; writer=writer, epoch=epoch)\n",
    "        isnan(avg_loss) && @warn \"Loss is NaN!\"\n",
    "        writer.\"add_scalar\"(\"dataset/neg_elbo\", avg_loss, epoch)\n",
    "\n",
    "        avg_eval = missing\n",
    "        if epoch % args[:eval_every] == 0\n",
    "            t_te += @elapsed avg_eval = evaluate(vae, te_loader)\n",
    "            writer.\"add_scalar\"(\"dataset/iwae_te\", avg_eval, epoch)\n",
    "            # Make visualisations\n",
    "            x_batch = first(te_loader)\n",
    "            write_vae(writer, vae, x_batch, epoch)\n",
    "        end\n",
    "\n",
    "        if epoch % args[:check_every] == 0\n",
    "            Knet.save(\"$model_path\", \"vae\", vae, \"epoch\", epoch)\n",
    "            @info \"Saved to `$model_path`\" epoch\n",
    "        end\n",
    "\n",
    "        @script ProgressMeter.next!(pm; showvalues = [(:epoch, epoch), (:loss, avg_loss), (:eval, avg_eval)])\n",
    "    end\n",
    "end\n",
    "@info \"Time\" t_total t_tr t_te\n",
    "\n",
    "@info \"Finished\"\n",
    "writer.\"add_scalar\"(\"dataset/iwae_tr\", evaluate(vae, tr_loader), epoch_end)\n",
    "\n",
    "if args[:store]\n",
    "    Knet.save(\"$model_path\", \"vae\", vae, \"epoch\", epoch_end)\n",
    "end\n",
    "\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For annotation purpose\n",
    "k_mode_rr = nothing\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect Z for the whole testset\n",
    "Z_list = []\n",
    "for x_batch in te_loader\n",
    "    dist_Z = vae(x_batch, Val(false))[3]\n",
    "    push!(Z_list, Array(mean(dist_Z)'))\n",
    "end\n",
    "\n",
    "# Make sure Z has the same number of columns by padding 0s\n",
    "# This is needed to be comptaible with RR methods\n",
    "n_cols_list = map(Z -> size(Z, 2), Z_list)\n",
    "n_cols_max = max(n_cols_list...)\n",
    "for i in 1:length(Z_list)\n",
    "    Z_list[i] = hcat(Z_list[i], zeros(size(Z_list[i], 1), n_cols_max - size(Z_list[i], 2)))\n",
    "end\n",
    "Z = vcat(Z_list...)\n",
    "if size(Z,2) < args[:k_max]\n",
    "    Z = hcat(Z, zeros(size(Z, 1), args[:k_max]-size(Z, 2)))\n",
    "end\n",
    "\n",
    "K_max = sum(sum(Z .> 0.01; dims=1) .> 0)\n",
    "@info \"Non-negligible posterior activation probability\" K_max\n",
    "\n",
    "# Output PDFs\n",
    "ps = make_Z_plot(Z; k_mode_rr=k_mode_rr, subplotting=false)\n",
    "for (i, fig_name) in enumerate([\"act\", \"freq\", \"hist\"])\n",
    "    writer.\"add_figure\"(\"plots/$fig_name\", ps[i])\n",
    "    ps[i].\"savefig\"(\"$log_dir/$fig_name.pdf\", bbox_inches=\"tight\")\n",
    "end\n",
    "@info \"Plots in PDF format saved to $log_dir/\"\n",
    "\n",
    "# Vis in Jupyter\n",
    "@jupyter make_Z_plot(Z; k_mode_rr=k_mode_rr, subplotting=true)\n",
    "\n",
    "# Report IWAE\n",
    "@info \"IWAE on training and testing set\" evaluate(vae, tr_loader) evaluate(vae, te_loader)\n",
    "\n",
    "# Vis features\n",
    "if args[:is_deep]\n",
    "    mu_list = []\n",
    "    for x_batch in te_loader\n",
    "        dist_A = vae(x_batch, Val(false))[4]\n",
    "        push!(mu_list, Array(mean(dist_A)'))\n",
    "    end\n",
    "    mu = vcat(mu_list...)\n",
    "    A_mean_avg = vec(mean(sqrt.(mu.^2); dims=1))\n",
    "    \n",
    "    p = plt.figure(figsize=(3,2))\n",
    "    plt.bar(1:length(A_mean_avg), A_mean_avg)\n",
    "    !(k_mode_rr === nothing) && plt.axvline(x=k_mode_rr, color=\"r\", linestyle=\"--\")\n",
    "    plt.xlabel(\"k-th feature\")\n",
    "    plt.ylabel(\"L1 norm of \" * L\"$q_{A_k}$\")\n",
    "    p.\"savefig\"(\"$log_dir/l2norm.pdf\", bbox_inches=\"tight\")\n",
    "else\n",
    "    p = plt.figure()\n",
    "    k = args[:inf] == \"rrs\" ? mode(value(vae.rho).lnpd) : args[:k_max]\n",
    "    ax = plot_grayimg(Array(vae.decoder.A[:,1:k]))\n",
    "    p.\"savefig\"(\"$log_dir/features.pdf\", bbox_inches=\"tight\")\n",
    "end\n",
    "\n",
    "# Vis posterior of truncation level\n",
    "if args[:inf] == \"rrs\"\n",
    "    # Report some stats\n",
    "    k_list = rand(value(vae.rho).lnpd, 1_000)\n",
    "    @info \"\" mode(value(vae.rho).lnpd) mean(k_list) std(k_list)\n",
    "    \n",
    "    rho = value(vae.rho)\n",
    "    ks = 1:(args[:k_max] > 1 ? args[:k_max] : vae.k_max)\n",
    "    ps = pdf.(Ref(rho), ks)\n",
    "    p = plt.figure(figsize=(3,3))\n",
    "    plt.plot(ks .- 1, ps)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(L\"P(K^*=k)\")\n",
    "    p.\"savefig\"(\"$log_dir/dist_k.pdf\", bbox_inches=\"tight\")\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not continue in script mode\n",
    "@script exit()\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other plots in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [1, 5, 10, 11, 12, 13, 14, 15, 20, 30, 50]\n",
    "\n",
    "iwae_list_tr = [evaluate(vae, tr_loader; k_max=k_max) for k_max in k_list]\n",
    "iwae_list_te = [evaluate(vae, te_loader; k_max=k_max) for k_max in k_list]\n",
    "@info \"\" iwae_list_tr iwae_list_te\n",
    "\n",
    "\n",
    "p = plt.figure(figsize=(3,2))\n",
    "plt.plot(k_list, iwae_list_tr, label=\"Tr. set\", \"--\", alpha=0.5)\n",
    "plt.plot(k_list, iwae_list_te, label=\"Te. set\", \"-+\", alpha=0.5)\n",
    "!(k_mode_rr === nothing) && plt.axvline(x=k_mode_rr, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"k_masked\")\n",
    "plt.ylabel(\"IWAE\")\n",
    "plt.legend()\n",
    "p.\"savefig\"(\"$log_dir/masked_iwae.pdf\", bbox_inches=\"tight\")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [10, 20, 50]\n",
    "\n",
    "time_list = [[@elapsed evaluate(vae, te_loader; k_max=k_max) for k_max in k_list] for _ = 1:3]\n",
    "@info \"\" time_list\n",
    "\n",
    "m = mean(time_list)\n",
    "s = std(time_list)\n",
    "\n",
    "p = plt.figure(figsize=(3,2))\n",
    "plt.plot(k_list, m, label=\"mean\")\n",
    "plt.plot(k_list, m - s, \"--\", color=\"grey\", label=\"std\")\n",
    "plt.plot(k_list, m + s, \"--\", color=\"grey\")\n",
    "!(k_mode_rr === nothing) && plt.axvline(x=k_mode_rr, color=\"r\", linestyle=\"--\")\n",
    "plt.xlabel(\"k_masked\")\n",
    "plt.ylabel(\"time (s)\")\n",
    "plt.xticks(k_list)\n",
    "plt.legend()\n",
    "p.\"savefig\"(\"$log_dir/time.pdf\", bbox_inches=\"tight\")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
